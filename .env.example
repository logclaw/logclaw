# ═══════════════════════════════════════════════════════════════════════════════
# LogClaw Environment Configuration
# ═══════════════════════════════════════════════════════════════════════════════
#
# Quick start:
#   cp .env.dev .env
#   make up
#
# Override any variable:
#   Edit .env, then run: make restart
#
# ═══════════════════════════════════════════════════════════════════════════════

# ── Identity ──────────────────────────────────────────────────────────────────
TENANT_ID=dev-local              # Tenant slug: dev-local | it-staging | uat | prod
STORAGE_CLASS=standard           # K8s StorageClass: standard | gp3 | premium-rwo

# ── Kafka ─────────────────────────────────────────────────────────────────────
# Set KAFKA_EXTERNAL=true to skip deploying in-cluster Kafka (Strimzi).
# When true, you MUST set KAFKA_BROKERS to your external Kafka bootstrap servers.
KAFKA_EXTERNAL=false
KAFKA_BROKERS=                   # Leave empty for auto-resolve; e.g. kafka.example.com:9092
KAFKA_TOPIC_RAW=raw-logs
KAFKA_TOPIC_ENRICHED=enriched-logs
KAFKA_TOPIC_ANOMALIES=anomaly-events

# ── OpenSearch ────────────────────────────────────────────────────────────────
# Set OPENSEARCH_EXTERNAL=true to skip deploying in-cluster OpenSearch.
# When true, you MUST set OPENSEARCH_ENDPOINT to your external cluster URL.
OPENSEARCH_EXTERNAL=false
OPENSEARCH_ENDPOINT=             # Leave empty for auto-resolve; e.g. https://os.example.com:9200

# ── Redis (ML-Engine feature store) ──────────────────────────────────────────
# Set REDIS_EXTERNAL=true to use an external Redis instead of deploying one.
REDIS_EXTERNAL=false
REDIS_URL=                       # e.g. redis://redis.example.com:6379

# ── PostgreSQL (Airflow metadata DB) ─────────────────────────────────────────
# Set POSTGRES_EXTERNAL=true to use an external PostgreSQL for Airflow.
POSTGRES_EXTERNAL=false
POSTGRES_HOST=                   # e.g. rds-postgres.example.com
POSTGRES_PORT=5432
POSTGRES_DB=airflow
POSTGRES_USER=airflow
POSTGRES_PASSWORD=

# ── Object Storage ────────────────────────────────────────────────────────────
OBJECT_STORAGE_PROVIDER=s3       # s3 | gcs | azure
OBJECT_STORAGE_BUCKET=logclaw-dev-local

# ── AI / ML ───────────────────────────────────────────────────────────────────
# LLM provider for Root Cause Analysis summary generation.
#   disabled — no LLM (raw anomaly data only)
#   ollama   — in-cluster Llama model (no API key, air-gapped)
#   vllm     — in-cluster vLLM server (set LLM_ENDPOINT)
#   claude   — Anthropic Claude API (set LLM_API_KEY in secret store)
#   openai   — OpenAI API (set LLM_API_KEY in secret store)
LLM_PROVIDER=disabled
LLM_MODEL=llama3.2:8b

# ── Ticketing ─────────────────────────────────────────────────────────────────
TICKETING_PLATFORM=pagerduty-jira
ZAMMAD_ENABLED=false             # Set true to deploy in-cluster Zammad ITSM

# ── Secret Store ──────────────────────────────────────────────────────────────
SECRET_STORE_NAME=logclaw-secret-store
SECRET_STORE_KIND=ClusterSecretStore

# ── Credentials ───────────────────────────────────────────────────────────────
# These are dev defaults. Override for real environments.
OPENSEARCH_ADMIN_USER=admin
OPENSEARCH_ADMIN_PASSWORD=admin
REDIS_PASSWORD=dev-redis-password
AIRFLOW_FERNET_KEY=ZGV2LWZlcm5ldC1rZXktMTIzNDU2Nzg5MGFiY2RlZj0=
AIRFLOW_WEBSERVER_SECRET=dev-webserver-secret
AIRFLOW_POSTGRES_PASSWORD=postgres
KAFKA_SASL_PASSWORD=dev-kafka-password
ZAMMAD_API_TOKEN=dev-zammad-token
ZAMMAD_ADMIN_EMAIL=admin@logclaw.local
ZAMMAD_ADMIN_PASSWORD=admin

# ── Port Forwarding ──────────────────────────────────────────────────────────
PORT_DASHBOARD=3333
PORT_ZAMMAD=3000
PORT_OPENSEARCH=9200
PORT_INGESTION=8080
PORT_TICKETING=8081
PORT_BRIDGE=8083
PORT_AIRFLOW=8082

# ═══════════════════════════════════════════════════════════════════════════════
# Environment Profiles Reference
# ═══════════════════════════════════════════════════════════════════════════════
#
# DEV (local Kind cluster):
#   TENANT_ID=dev-local
#   All *_EXTERNAL=false (everything runs in-cluster)
#   LLM_PROVIDER=disabled
#
# IT (integration testing):
#   TENANT_ID=it-staging
#   KAFKA_EXTERNAL=true, KAFKA_BROKERS=kafka-it.internal:9092
#   OPENSEARCH_EXTERNAL=false (own cluster)
#   LLM_PROVIDER=disabled
#
# UAT (user acceptance):
#   TENANT_ID=uat
#   All *_EXTERNAL=true (shared infrastructure)
#   LLM_PROVIDER=claude
#   ZAMMAD_ENABLED=true
#
# PROD:
#   TENANT_ID=prod
#   All *_EXTERNAL=true
#   STORAGE_CLASS=gp3
#   LLM_PROVIDER=claude
#   tier=ha (set in tenant YAML, not here)
#
# ═══════════════════════════════════════════════════════════════════════════════
