nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

flink:
  version: "1.19"
  jobImageTag: "0.1.0"

  # Flink configuration overrides (merged into flink-conf.yaml)
  config:
    taskmanager.numberOfTaskSlots: "4"
    state.backend: "rocksdb"
    state.backend.rocksdb.use-bloom-filter: "true"
    execution.checkpointing.interval: "30s"
    execution.checkpointing.mode: "EXACTLY_ONCE"
    execution.checkpointing.timeout: "60s"
    metrics.reporters: "prom"
    metrics.reporter.prom.class: "org.apache.flink.metrics.prometheus.PrometheusReporter"
    metrics.reporter.prom.port: "9249"
    rest.flamegraph.enabled: "true"
    kubernetes.operator.periodic.reconcile.interval: "30s"

  jobManager:
    cpu: 1
    memory: "2048m"
    replicas: 1

  taskManager:
    cpu: 2
    memory: "4096m"
    replicas: 2
    resources:
      requests:
        cpu: "2"
        memory: "4Gi"
      limits:
        cpu: "4"
        memory: "8Gi"

  # ETL/parsing job
  etlJob:
    enabled: true
    parallelism: 4
    jar: "logclaw-etl-{{ .Values.flink.jobImageTag }}.jar"
    entryClass: "io.logclaw.flink.EtlParsingJob"

  # Enrichment job
  enrichmentJob:
    enabled: true
    parallelism: 4
    jar: "logclaw-enrichment-{{ .Values.flink.jobImageTag }}.jar"
    entryClass: "io.logclaw.flink.EnrichmentJob"

  # Anomaly scoring job (sub-200ms SLO)
  anomalyJob:
    enabled: true
    parallelism: 8
    jar: "logclaw-anomaly-scorer-{{ .Values.flink.jobImageTag }}.jar"
    entryClass: "io.logclaw.flink.AnomalyScoringJob"

  sessionCluster:
    enabled: false

podDisruptionBudget:
  minAvailable: 1
